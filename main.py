import os
import re
import requests
import discord
from discord.ext import commands
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from threading import Thread
from flask import Flask
import time

# --- 1. Webã‚µãƒ¼ãƒãƒ¼è¨­å®š (Keep Aliveç”¨) ---
app = Flask('')
@app.route('/')
def home(): return "Bot is running!"

def run_web():
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port)

def keep_alive():
    t = Thread(target=run_web)
    t.daemon = True
    t.start()

# --- 2. è¨­å®šã¨ç’°å¢ƒå¤‰æ•° ---
load_dotenv()
TOKEN = os.getenv('DISCORD_TOKEN') or os.getenv('DISCORD_BOT_TOKEN')
AMAZON_TAG = os.getenv('AMAZON_TAG', 'default-tag-22')

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8', 
}

# å¤šè¨€èªãƒ»é€šè²¨è¨­å®šã®è¾æ›¸
LOCALE_SETTINGS = {
    "amazon.co.jp": {
        "lang": "ja", "currency": "ï¿¥", "price": "ä¾¡æ ¼", 
        "rating": "è©•ä¾¡", "reviews": "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", "comment": "ã‚³ãƒ¡ãƒ³ãƒˆ", "shared": "æŠ•ç¨¿è€…"
    },
    "amazon.com": {
        "lang": "en", "currency": "$", "price": "Price", 
        "rating": "Rating", "reviews": "Reviews", "comment": "Comment", "shared": "Shared by"
    },
    "amazon.co.uk": {
        "lang": "en", "currency": "Â£", "price": "Price", 
        "rating": "Rating", "reviews": "Reviews", "comment": "Comment", "shared": "Shared by"
    }
}
DEFAULT_LOCALE = {
    "lang": "en", "currency": "$", "price": "Price", 
    "rating": "Rating", "reviews": "Reviews", "comment": "Comment", "shared": "Shared by"
}

# --- 3. å‡¦ç†é–¢æ•° ---

def get_og_data(url):
    """ä¸€èˆ¬ã‚µã‚¤ãƒˆã®ãƒ‡ãƒ¼ã‚¿å–å¾— & ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å‰Šé™¤"""
    try:
        clean_url = url.split('?')[0]
        res = requests.get(clean_url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        title_tag = soup.find('meta', property='og:title') or soup.find('title')
        title = title_tag['content'] if title_tag and title_tag.has_attr('content') else (title_tag.text if title_tag else "Link")
        
        img_tag = soup.find('meta', property='og:image')
        img_url = img_tag['content'] if img_tag else ""
        
        return title.strip()[:60], img_url, clean_url
    except:
        return "Link", "", url.split('?')[0]

def scrape_amazon_data(url):
    """Amazonã®å•†å“æƒ…å ±ã‚’å–å¾—"""
    try:
        time.sleep(1) 
        res = requests.Session().get(url, headers=HEADERS, timeout=15)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        title = soup.find(id='productTitle')
        title = title.get_text().strip() if title else "Amazon Product"
        
        price_elem = soup.select_one('.a-price .a-offscreen') or soup.select_one('.a-price-whole')
        price = price_elem.get_text().strip() if price_elem else "N/A"

        rating = "N/A"
        r_elem = soup.select_one('span.a-icon-alt')
        if r_elem:
            m = re.search(r'(\d[\.,]\d)', r_elem.get_text())
            if m: rating = f"â­ {m.group(1)}"

        reviews = "0"
        rev_elem = soup.find(id='acrCustomerReviewText')
        if rev_elem:
            c = re.sub(r'\D', '', rev_elem.get_text())
            if c: reviews = "{:,}".format(int(c))
        
        img = soup.find(id='landingImage') or soup.find('meta', property='og:image')
        img_url = img.get('src') if img and not img.get('content') else (img.get('content') if img else "")
        
        asin_match = re.search(r'/(?:dp|gp/product)/([A-Z0-9]{10})', res.url)
        asin = asin_match.group(1) if asin_match else None
        
        return title[:50], price, rating, reviews, img_url, asin
    except:
        return None

def process_amazon(url, author, user_comment):
    """Amazonç”¨UI (è¨€èªãƒ»é€šè²¨è‡ªå‹•åˆ‡ã‚Šæ›¿ãˆ)"""
    data = scrape_amazon_data(url)
    if not data: return None
    
    title, price, rating, reviews, img, asin = data
    domain = next((d for d in LOCALE_SETTINGS if d in url), "amazon.com")
    config = LOCALE_SETTINGS.get(domain, DEFAULT_LOCALE)
    
    clean_price_num = re.sub(r'[^\d\.,]', '', price)
    display_price = f"{config['currency']}{clean_price_num}" if clean_price_num else price

    clean_url = f"https://{domain}/dp/{asin}" if asin else url.split('?')[0]
    tagged_url = f"{clean_url}?tag={AMAZON_TAG}"
    
    embed = discord.Embed(title=title, url=tagged_url, color=0xff9900)
    if user_comment:
        embed.description = f"**{config['comment']}:**\n{user_comment}"
    
    embed.add_field(name=config['price'], value=display_price, inline=True)
    embed.add_field(name=config['rating'], value=rating, inline=True)
    embed.add_field(name=config['reviews'], value=reviews, inline=True)
    
    if img: embed.set_thumbnail(url=img)
    embed.set_footer(text=f"{config['shared']} {author.display_name} | {domain}")
    return embed

# --- 4. Botãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
intents = discord.Intents.default()
intents.message_content = True 
bot = commands.Bot(command_prefix="!", intents=intents)

@bot.event
async def on_ready():
    print(f'âœ… {bot.user} Online (Exclude List Active)')

@bot.event
async def on_message(message):
    if message.author.bot: return
    
    found_urls = re.findall(r'https?://[^\s]+', message.content)
    if not found_urls: return

    target_url = found_urls[0].lower()

    # --- ã€æ–°è¦è¿½åŠ ã€‘é™¤å¤–ãƒªã‚¹ãƒˆ ---
    exclude_domains = [
        "youtube.com", "youtu.be",      # å‹•ç”»
        "twitter.com", "x.com",        # SNS
        "instagram.com", "tiktok.com",   # SNS
        "facebook.com",                 # SNS
        "spotify.com", "apple.com",     # éŸ³æ¥½
        "twitch.tv", "nicovideo.jp",    # é…ä¿¡
        "pixiv.net", "note.com",        # ã‚¤ãƒ©ã‚¹ãƒˆãƒ»è¨˜äº‹
        "discord.com"                   # å†…éƒ¨ãƒªãƒ³ã‚¯
    ]
    
    # é™¤å¤–å¯¾è±¡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå«ã¾ã‚Œã¦ã„ãŸã‚‰ä½•ã‚‚ã—ãªã„
    if any(domain in target_url for domain in exclude_domains):
        return

    # å‡¦ç†é–‹å§‹
    status_msg = await message.channel.send("âŒ› **Processing Link...**")
    
    clean_comment = message.content
    for u in found_urls:
        clean_comment = clean_comment.replace(u, "")
    clean_comment = clean_comment.strip()

    # A. Amazon
    if "amazon." in target_url or "amzn." in target_url:
        embed = process_amazon(found_urls[0], message.author, clean_comment)
        if embed:
            try:
                await message.delete()
                await status_msg.edit(content=None, embed=embed)
                return
            except: pass

    # B. Amazonä»¥å¤– (AliExpress, æ¥½å¤©, Yahooãªã©)
    if len(target_url) > 60 or any(d in target_url for d in ["aliexpress", "rakuten", "yahoo"]):
        title, img, clean_link = get_og_data(found_urls[0])
        domain_match = re.search(r'https?://([^/]+)', clean_link)
        domain = domain_match.group(1) if domain_match else "Link"
        
        desc = f"[{domain}]({clean_link})"
        if clean_comment:
            desc = f"**Comment:**\n{clean_comment}\n\n" + desc

        short_embed = discord.Embed(title=f"ğŸ”— {title}", description=desc, color=0xcccccc)
        if img: short_embed.set_thumbnail(url=img)
        short_embed.set_footer(text=f"Shared by {message.author.display_name}")

        try:
            await message.delete()
            await status_msg.edit(content=None, embed=short_embed)
        except: pass
    else:
        # ã©ã¡ã‚‰ã«ã‚‚è©²å½“ã—ãªã„ï¼ˆçŸ­ã„æ™®é€šã®ãƒªãƒ³ã‚¯ç­‰ï¼‰å ´åˆã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¶ˆã™
        await status_msg.delete()

# --- 5. å®Ÿè¡Œ ---
if __name__ == "__main__":
    keep_alive()
    bot.run(TOKEN)